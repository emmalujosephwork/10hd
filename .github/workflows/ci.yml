name: CI Pipeline

on:
  push:
    branches:
      - testing
      - main

jobs:
  # 1. Run Tests
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - run: python -m pip install --upgrade pip
      - name: Create DBs
        run: |
          sudo apt-get install -y postgresql-client
          for db in customers orders products; do
            PGPASSWORD=postgres psql -h localhost -U postgres -d testdb -c "CREATE DATABASE $db;" || true
          done
      - name: Run Tests
        run: |
          pip install -r backend/customer_service/requirements-dev.txt
          cd backend/customer_service && pytest -v --disable-warnings
          cd ../..
          pip install -r backend/order_service/requirements-dev.txt
          cd backend/order_service && pytest -v --disable-warnings
          cd ../..
          pip install -r backend/product_service/requirements-dev.txt
          cd backend/product_service && pytest -v --disable-warnings

  # 2. Build & Push Images
  build-and-push:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v3
      - uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Login to ACR
        uses: azure/docker-login@v1
        with:
          login-server: sit722acremmalu.azurecr.io
          username: ${{ secrets.ACR_USERNAME }}
          password: ${{ secrets.ACR_PASSWORD }}
      - name: Build & Push Images
        run: |
          docker build -t sit722acremmalu.azurecr.io/customer-service:${{ github.sha }} ./backend/customer_service
          docker push sit722acremmalu.azurecr.io/customer-service:${{ github.sha }}
          docker build -t sit722acremmalu.azurecr.io/order-service:${{ github.sha }} ./backend/order_service
          docker push sit722acremmalu.azurecr.io/order-service:${{ github.sha }}
          docker build -t sit722acremmalu.azurecr.io/product-service:${{ github.sha }} ./backend/product_service
          docker push sit722acremmalu.azurecr.io/product-service:${{ github.sha }}
          docker build -t sit722acremmalu.azurecr.io/frontend-service:${{ github.sha }} ./frontend
          docker push sit722acremmalu.azurecr.io/frontend-service:${{ github.sha }}

  # 3. Deploy to Staging (testing branch → temporary cluster)
  staging-deploy:
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.ref == 'refs/heads/testing'
    steps:
      - uses: actions/checkout@v3
      - uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Ensure Resource Group & Cluster
        run: |
          az group create --name sit722-staging-rg --location australiaeast
          if ! az aks show --name sit722-aks-staging --resource-group sit722-staging-rg &>/dev/null; then
            az aks create \
              --resource-group sit722-staging-rg \
              --name sit722-aks-staging \
              --node-count 1 \
              --node-vm-size Standard_B2s \
              --generate-ssh-keys
          fi
          az aks get-credentials --resource-group sit722-staging-rg --name sit722-aks-staging --overwrite-existing
      - name: Create Namespace & Secret
        run: |
          kubectl create namespace staging || true
          kubectl delete secret acr-secret -n staging --ignore-not-found
          kubectl create secret docker-registry acr-secret \
            --docker-server=sit722acremmalu.azurecr.io \
            --docker-username=${{ secrets.ACR_USERNAME }} \
            --docker-password=${{ secrets.ACR_PASSWORD }} \
            -n staging
      - name: Patch Manifests with Commit SHA
        run: sed -i "s|:staging|:${{ github.sha }}|g" k8s/staging/*.yaml
      - name: Deploy Manifests
        run: kubectl apply -f k8s/staging/ -n staging
      - name: Smoke Test
        run: |
          kubectl rollout status deployment/customer-deployment -n staging --timeout=180s
          kubectl rollout status deployment/order-deployment -n staging --timeout=180s
          kubectl rollout status deployment/product-deployment -n staging --timeout=180s
          kubectl rollout status deployment/frontend-deployment -n staging --timeout=180s
          kubectl get pods -n staging
          kubectl get svc -n staging
      - name: Cleanup Staging Cluster
        if: always()
        run: az group delete --name sit722-staging-rg --yes --no-wait

  # 4. Deploy to Production (main branch → persistent cluster)
  production-deploy:
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3
      - uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Get AKS Credentials
        run: az aks get-credentials --resource-group sit722-rg --name sit722-aks-prod --overwrite-existing
      - name: Create Namespace & Secret
        run: |
          kubectl create namespace production || true
          kubectl delete secret acr-secret -n production --ignore-not-found
          kubectl create secret docker-registry acr-secret \
            --docker-server=sit722acremmalu.azurecr.io \
            --docker-username=${{ secrets.ACR_USERNAME }} \
            --docker-password=${{ secrets.ACR_PASSWORD }} \
            -n production
      - name: Patch Manifests with Commit SHA
        run: sed -i "s|:latest|:${{ github.sha }}|g" k8s/production/*.yaml
      - name: Deploy Manifests
        run: kubectl apply -f k8s/production/ -n production
      - name: Verify Deployment
        run: |
          kubectl rollout status deployment/customer-deployment -n production --timeout=180s
          kubectl rollout status deployment/order-deployment -n production --timeout=180s
          kubectl rollout status deployment/product-deployment -n production --timeout=180s
          kubectl rollout status deployment/frontend-deployment -n production --timeout=180s
          kubectl get pods -n production
          kubectl get svc -n production
      - name: Rollback on Failure
        if: failure()
        run: |
          kubectl rollout undo deployment/customer-deployment -n production || true
          kubectl rollout undo deployment/order-deployment -n production || true
          kubectl rollout undo deployment/product-deployment -n production || true
          kubectl rollout undo deployment/frontend-deployment -n production || true
